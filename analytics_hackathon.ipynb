{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h1 align=\"center\"> Generative AI Hackathon</h1>\n",
        "<table align=\"center\">\n",
        "    <td>\n",
        "        <a href=\"https://colab.research.google.com/github/teamdatatonic/gen-ai-hackathon/blob/main/hackathon.ipynb\">\n",
        "            <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\">\n",
        "            <span style=\"vertical-align: middle;\">Run in Colab</span>\n",
        "        </a>\n",
        "    </td>\n",
        "    <td>\n",
        "        <a href=\"https://github.com/teamdatatonic/gen-ai-hackathon/blob/main/hackathon.ipynb\">\n",
        "            <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
        "            <span style=\"vertical-align: middle;\">View on GitHub</span>\n",
        "        </a>\n",
        "    </td>\n",
        "    <td>\n",
        "        <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/teamdatatonic/gen-ai-hackathon/main/hackathon.ipynb\">\n",
        "            <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\"> \n",
        "            <span style=\"vertical-align: middle;\">Open in Vertex AI Workbench</span>\n",
        "        </a>\n",
        "    </td>\n",
        "</table>\n",
        "<hr>\n",
        "\n",
        "**➡️ Your task:** Learn about Generative AI by building your own Database Analytics using Python and LangChain!\n",
        "\n",
        "**❗ Note:** This workshop has been designed to be run in Google CoLab. Support for running the workshop locally or using VertexAI Workbench is provided, but we heavily recommend CoLab for the best experience.\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**❗ Note:** If your kernel doesn't restart automatically, click the \"Restart Runtime\" button above your notebook.\n",
        "If you dont see a restart button, go to the \"Runtime\" toolbar tab then \"Restart Runtime\". After restarting, continue executing the project from below this cell.\n",
        "\n",
        "## Accessing the Vertex AI Endpoint\n",
        "\n",
        "Currently, Vertex AI LLMs are accessible via Google Cloud projects. \n",
        "\n",
        "1. Set the env variables `project_id` and `dataset_id` with the filepath (**❗ Note:** the `/content/` folder is where uploaded files are stored by default)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Replace 'your-project-id' with your Google Cloud project ID\n",
        "project_id = 'dt-genai-analytics-dev'\n",
        "dataset_id = 'database_analytics_demo_v2'"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Setting up the BigQuery client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Datasets in project dt-genai-analytics-dev:\n",
            "database_analytics_demo_v2\n",
            "logging\n"
          ]
        }
      ],
      "source": [
        "from google.cloud import bigquery\n",
        "\n",
        "\n",
        "# Initialize the BigQuery client\n",
        "client = bigquery.Client(project=project_id)\n",
        "\n",
        "# Test the connection by listing datasets in the project\n",
        "datasets = list(client.list_datasets())\n",
        "print(\"Datasets in project {}:\".format(project_id))\n",
        "if datasets:\n",
        "    for dataset in datasets:\n",
        "        print(\"{}\".format(dataset.dataset_id))\n",
        "else:\n",
        "    print(\"No datasets found in project {}\".format(project_id))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Pip install package dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %pip install pybigquery\n",
        "# %pip install SQLAlchemy==1.4.49\n",
        "# %pip install pyarrow\n",
        "# %pip install google-cloud-bigquery-storage\n",
        "# %pip install sqlalchemy-bigquery==1.7.0\n",
        "# %pip install google-cloud-aiplatform"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create database engine and SQL chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new  chain...\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/roberta/.pyenv/versions/3.10.9/lib/python3.10/site-packages/langchain/chains/llm.py:275: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Table names to use:\n",
            "\u001b[33;1m\u001b[1;3m['customers']\u001b[0m\n",
            "\n",
            "\u001b[1m> Entering new  chain...\u001b[0m\n",
            "How many customers are there?\n",
            "SQLQuery:\u001b[32;1m\u001b[1;3mSELECT count(*) FROM customers\u001b[0m\n",
            "SQLResult: \u001b[33;1m\u001b[1;3m[(1000,)]\u001b[0m\n",
            "Answer:\u001b[32;1m\u001b[1;3m1000\u001b[0m\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'query': 'How many customers are there?', 'result': '1000'}"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "from langchain.chains.sql_database.base import SQLDatabaseChain\n",
        "from langchain.chains import SQLDatabaseSequentialChain\n",
        "from langchain.sql_database import SQLDatabase\n",
        "from langchain.llms import VertexAI\n",
        "from sqlalchemy.engine import create_engine\n",
        "\n",
        "\n",
        "engine = create_engine(f\"bigquery://{project_id}/{dataset_id}\")\n",
        "\n",
        "llm = VertexAI(model_name='text-bison@001',\n",
        "               temperature=0, max_output_tokens=1024)\n",
        "\n",
        "db = SQLDatabase(engine=engine)\n",
        "\n",
        "\n",
        "db_chain = SQLDatabaseSequentialChain.from_llm(\n",
        "        llm,\n",
        "        db,\n",
        "        verbose=True\n",
        "    )\n",
        "\n",
        "# test questions\n",
        "# db_chain(\"How many employees are there?\")\n",
        "# db_chain(\"total_revenue\")\n",
        "db_chain(\"How many customers are there?\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "vscode": {
      "interpreter": {
        "hash": "9ea5ffafec065a5b064a6fab7872630ad2c79ca3c7ae1da3bf097c85297990f4"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
