{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\"> Generative AI Hackathon</h1>\n",
    "<table align=\"center\">\n",
    "    <!-- <td>\n",
    "        <a href=\"https://colab.research.google.com/github/teamdatatonic/gen-ai-hackathon/blob/feature/DBA-hackathon/notebook/analytics_hackathon.ipynb\">\n",
    "            <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\">\n",
    "            <span style=\"vertical-align: middle;\">Run in Colab</span>\n",
    "        </a>\n",
    "    </td> -->\n",
    "    <!-- <td>\n",
    "        <a href=\"https://github.com/teamdatatonic/gen-ai-hackathon/blob/DBA-hackathon/analytics_hackathon.ipynb\">\n",
    "            <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
    "            <span style=\"vertical-align: middle;\">View on GitHub</span>\n",
    "        </a>\n",
    "    </td> -->\n",
    "    <!-- <td>\n",
    "        <a href=\"http://127.0.0.1:8888/?token=30f0873aab701a416cc3cc4be5926caa89940d3778fcef47\n",
    "        \">\n",
    "            <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\"> \n",
    "            <span style=\"vertical-align: middle;\">Open in Jupyter Notebook</span>\n",
    "        </a>\n",
    "    </td> -->\n",
    "</table>\n",
    "<hr>\n",
    "\n",
    "**➡️ Your task:** Learn about Generative AI by building your own Analytics Assistant using Python and LangChain!\n",
    "\n",
    "**❗ Note:** This workshop has been designed to be run in Jupyter Notebook. A credentials.json key will be shared with you for the purpose of running this project. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pip install package dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install --quiet \"git+https://github.com/teamdatatonic/gen-ai-hackathon.git@feat/alvaro#egg=dt-gen-ai-analytics-helper\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!poetry install \n",
    "!poetry export --format requirements.txt --output requirements.txt\n",
    "%pip install -r requirements.txt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Launch Jupyter Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!poetry run jupyter notebook"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**❗ Note:** This notebook will keep running until it is shut down manually."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analytics Assistant Hackathon - Start Here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vertex AI Endpoint\n",
    "\n",
    "Currently, Vertex AI LLMs are accessible via Google Cloud projects. \n",
    "\n",
    "1. Set the env variables `project_id` and `dataset_id` with the filepath (**❗ Note:** the `/content/` folder is where uploaded files are stored by default)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 'your-project-id' with your Google Cloud project ID\n",
    "PROJECT_ID = 'dt-gen-ai-hackathon-dev'\n",
    "DATASET_ID = 'database_analytics_demo_v2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# @title Set project credentials. { run: \"auto\", display-mode: \"form\" }\n",
    "# @markdown Set the filepath to the `.json` credentials file.\n",
    "\n",
    "GOOGLE_APPLICATION_CREDENTIALS = \"credentials.json\"  # @param {type:\"string\"}\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = GOOGLE_APPLICATION_CREDENTIALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud config set account dt-gen-ai-hackathon-sa@dt-gen-ai-hackathon-dev.iam.gserviceaccount.com\n",
    "!gcloud auth activate-service-account --key-file={GOOGLE_APPLICATION_CREDENTIALS}\n",
    "!gcloud config set project {PROJECT_ID}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.sql.base import SQLDatabaseSequentialChain\n",
    "from langchain.agents.agent_toolkits import SQLDatabaseToolkit\n",
    "from langchain.agents import(create_pandas_dataframe_agent)\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from langchain.agents.agent_types import AgentType\n",
    "from langchain.sql_database import SQLDatabase\n",
    "from langchain import LLMChain,PromptTemplate\n",
    "from langchain.agents import create_sql_agent \n",
    "from sqlalchemy.engine import create_engine\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from sqlalchemy import create_engine\n",
    "from langchain.llms import VertexAI\n",
    "from langchain import SQLDatabase\n",
    "from tabulate import tabulate\n",
    "from datetime import date\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import gradio as gr\n",
    "import time"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Begin the Hackathon\n",
    "\n",
    "- Set up the Bigquery Database\n",
    "- Set up LLM Chain \n",
    "- Example query to LLM"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Bigquery Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Database:\n",
    "    def __init__(self, url: str, schema: str = None):\n",
    "        print(\"creating db engine...\")\n",
    "        self.engine = self.create_engine(url)\n",
    "        print(\"creating db session...\")\n",
    "        self.base = declarative_base()\n",
    "        self.sessionmaker = sessionmaker(\n",
    "            autocommit=True, autoflush=True, bind=self.engine\n",
    "        )\n",
    "        self.schema = schema\n",
    "        print(\"creating db connection...\")\n",
    "        self.connect = self.engine.connect()\n",
    "\n",
    "    def create_engine(self, url):\n",
    "        return create_engine(url)\n",
    "\n",
    "    @property\n",
    "    def dialect(self) -> str:\n",
    "        return self.engine.dialect.name\n",
    "\n",
    "    def create_session(self):\n",
    "        return self.sessionmaker()\n",
    "    \n",
    "    def create_connection(self):\n",
    "        return  self.connect\n",
    "    \n",
    "\n",
    "class BigQueryDatabase(Database):\n",
    "    def __init__(\n",
    "        self,\n",
    "        project_id=PROJECT_ID,\n",
    "        dataset_id=DATASET_ID,\n",
    "    ):\n",
    "        super().__init__(f\"bigquery://{project_id}/{dataset_id}\")\n",
    "        self.schema = dataset_id"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create LLM Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "TEST_PROMPT = '''\n",
    "You are a GoogleSQL expert. Given an input question, first create a syntactically\n",
    "correct GoogleSQL query to run, then look at the results of the query and return\n",
    "the answer to the input question:{question}\n",
    "'''\n",
    "\n",
    "def create_sql_chain(llm, db, question):\n",
    "    \"\"\" Create a Q&A conversation chain using the VertexAI LLM.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    db_chain = SQLDatabaseSequentialChain.from_llm(\n",
    "        llm,\n",
    "        db,\n",
    "        verbose=True,\n",
    "        return_intermediate_steps=True,\n",
    "    )\n",
    "    test_prompt = PromptTemplate(template=TEST_PROMPT, input_variables=[\"question\"])\n",
    "\n",
    "    output = db_chain(test_prompt.format(question=question))\n",
    "    sql_query = output[\"intermediate_steps\"][1]\n",
    "    response = output[\"result\"]\n",
    "    \n",
    "    return response, sql_query\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Intialize two LLM types - Code generation and Text generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize text generation LLM\n",
    "llm = VertexAI(model_name='text-bison@001',\n",
    "               temperature=0, max_output_tokens=1024)\n",
    "\n",
    "# Initialize code generation LLM\n",
    "code_llm = VertexAI(model_name='code-bison@001', temperature=0, max_output_tokens=1024)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = BigQueryDatabase(project_id=PROJECT_ID, dataset_id=DATASET_ID)\n",
    "session = db.create_session()\n",
    "\n",
    "conn = db.create_connection()\n",
    "\n",
    "langchain_db = SQLDatabase(\n",
    "    db.engine, schema=db.schema, sample_rows_in_table_info=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Code generation LLM with Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to query the SQLDBChain\n",
    "def query_database(question, llm ,db):\n",
    "    \n",
    "    # Call the SQLDBChain to get the answer based on the question\n",
    "    answer, sql_query = create_sql_chain(llm=llm, db=langchain_db, question)\n",
    "\n",
    "    return answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "query_database('How many customers are there?')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 : Create LLM Chain\n",
    "\n",
    "This part of the hackathon will be up to you to implement. We have provided example code for you to use as examples but its up to you what you create!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1 \n",
    "\n",
    "- Can you write a better prompt?\n",
    "- How can this prompt be used to improve the performance of the LLM?\n",
    "- Can we use different LLMs to achiveve better performance? Eg. code generation and Text generation LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Create Simple Gradio Interface "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Create SQL Agent with ToolKit\n",
    "\n",
    "Now that we have a more capable LLM and gradio interface implemented, can we make it better? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Create Gradio chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Create Pandas Agent\n",
    "\n",
    "Now that we have made an SQLAgent and a Gradio chatbot, we can go further and make a Data Analytics agent that is able to perform analysis and plot relevant charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "9ea5ffafec065a5b064a6fab7872630ad2c79ca3c7ae1da3bf097c85297990f4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
