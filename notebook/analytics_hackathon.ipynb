{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\"> Generative AI Hackathon</h1>\n",
    "<table align=\"center\">\n",
    "    <!-- <td>\n",
    "        <a href=\"https://colab.research.google.com/github/teamdatatonic/gen-ai-hackathon/blob/feature/DBA-hackathon/notebook/analytics_hackathon.ipynb\">\n",
    "            <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\">\n",
    "            <span style=\"vertical-align: middle;\">Run in Colab</span>\n",
    "        </a>\n",
    "    </td> -->\n",
    "    <!-- <td>\n",
    "        <a href=\"https://github.com/teamdatatonic/gen-ai-hackathon/blob/DBA-hackathon/analytics_hackathon.ipynb\">\n",
    "            <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
    "            <span style=\"vertical-align: middle;\">View on GitHub</span>\n",
    "        </a>\n",
    "    </td> -->\n",
    "    <!-- <td>\n",
    "        <a href=\"http://127.0.0.1:8888/?token=30f0873aab701a416cc3cc4be5926caa89940d3778fcef47\n",
    "        \">\n",
    "            <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\"> \n",
    "            <span style=\"vertical-align: middle;\">Open in Jupyter Notebook</span>\n",
    "        </a>\n",
    "    </td> -->\n",
    "</table>\n",
    "<hr>\n",
    "\n",
    "**➡️ Your task:** Learn about Generative AI by building your own Database Analytics using Python and LangChain!\n",
    "\n",
    "**❗ Note:** This workshop has been designed to be run in Jupyter Notebook. A credentials.json key will be shared with you for the purpose of running this project. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pip install package dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!poetry install \n",
    "!poetry export --format requirements.txt --output requirements.txt\n",
    "%pip install -r requirements.txt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**❗ Note:** This notebook will keep running until it is shut down manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!poetry run jupyter notebook"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing the Vertex AI Endpoint\n",
    "\n",
    "Currently, Vertex AI LLMs are accessible via Google Cloud projects. \n",
    "\n",
    "1. Set the env variables `project_id` and `dataset_id` with the filepath (**❗ Note:** the `/content/` folder is where uploaded files are stored by default)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 'your-project-id' with your Google Cloud project ID\n",
    "project_id = 'dt-gen-ai-hackathon-dev'\n",
    "dataset_id = 'database_analytics_demo_v2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# @title Set project credentials. { run: \"auto\", display-mode: \"form\" }\n",
    "# @markdown Set the filepath to the `.json` credentials file.\n",
    "\n",
    "GOOGLE_APPLICATION_CREDENTIALS = \"credentials.json\"  # @param {type:\"string\"}\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = GOOGLE_APPLICATION_CREDENTIALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated property [core/account].\n"
     ]
    }
   ],
   "source": [
    "!gcloud config set account dt-gen-ai-hackathon-sa@dt-gen-ai-hackathon-dev.iam.gserviceaccount.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activated service account credentials for: [dt-gen-ai-hackathon-sa@dt-gen-ai-hackathon-dev.iam.gserviceaccount.com]\n"
     ]
    }
   ],
   "source": [
    "!gcloud auth activate-service-account --key-file={GOOGLE_APPLICATION_CREDENTIALS}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n"
     ]
    }
   ],
   "source": [
    "!gcloud config set project {project_id}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the BigQuery client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery, aiplatform\n",
    "\n",
    "# Initialize the BigQuery client\n",
    "client = bigquery.Client(project=project_id)\n",
    "\n",
    "# Initialise AI Platform\n",
    "aiplatform.init(project=project_id)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create SQL chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cloudpickle is not installed. Please call `pip install google-cloud-aiplatform[preview]`.\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SQLDatabaseChain chain...\u001b[0m\n",
      "How many customers are there?\n",
      "SQLQuery:\u001b[32;1m\u001b[1;3mSELECT COUNT(*) FROM customers\u001b[0m\n",
      "SQLResult: \u001b[33;1m\u001b[1;3m[(1000,)]\u001b[0m\n",
      "Answer:\u001b[32;1m\u001b[1;3mThere are 1000 customers.\u001b[0m\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'How many customers are there?',\n",
       " 'result': 'There are 1000 customers.'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_experimental.sql import SQLDatabaseChain\n",
    "from langchain.sql_database import SQLDatabase\n",
    "from langchain.llms import VertexAI\n",
    "from sqlalchemy.engine import create_engine\n",
    "\n",
    "\n",
    "\n",
    "engine = create_engine(f\"bigquery://{project_id}/{dataset_id}\")\n",
    "\n",
    "llm = VertexAI(model_name='text-bison@001',\n",
    "               temperature=0, max_output_tokens=1024)\n",
    "\n",
    "db = SQLDatabase(engine=engine)\n",
    "\n",
    "\n",
    "db_chain = SQLDatabaseChain.from_llm(\n",
    "        llm,\n",
    "        db,\n",
    "        verbose=True\n",
    "    )\n",
    "\n",
    "# Some test questions\n",
    "# db_chain(\"How many employees are there?\")\n",
    "# db_chain(\"total_revenue\")\n",
    "db_chain(\"How many customers are there?\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "9ea5ffafec065a5b064a6fab7872630ad2c79ca3c7ae1da3bf097c85297990f4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
